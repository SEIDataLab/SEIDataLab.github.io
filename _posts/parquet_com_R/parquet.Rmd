---
title: "Parquet para grandes conjuntos de dados no R"
description: |
 Apesar do formato csv ser largamente adotado, quando o conjuntos de dados é grande, o csv apresenta limitações. Nesses casos, pode ser vantajoso optar pelo Parquet, um  formato de arquivo para armazenamento de dados orientado a colunas. Abordamos aqui a performance de arquivos Parquet no R através da biblioteca Arrow da Apache Foundation. Foi utilizado como exemplos os microdados do Censo Escolar 2019, disponibilizados pelo INEP - Ministério da Educação do Brasil.
preview: parquet.png
author:
  - name: Jonatas Silva do Espirito Santo 
    url: https://github.com/jonates/
    affiliation: Diretor de Pesquisas | SEI - Governo da Bahia
    affiliation_url: www.sei.ba.gov.br
    orcid_id: 0000-0002-1654-0314
date: 02-15-2021
output:
  distill::distill_article:
    self_contained: false
---
<style>
body {
text-align: justify}
</style>

Já se passaram décadas após a criação do `csv`, mas ainda é rotina entre as intituições, seja no setor privado, seja nas instituições públicas, armazenar dados em um arquivo `csv` (“comma-separated-values”), que como próprio significado da sigla já diz, é um arquivo com valores separados por vírgulas. Vale ressaltar que, como no Brasil a vírgula é utilizada como separador de casa decimal, então é prática comum utilizar o sinal ponto e vírgula (;) como separador de valores, em vez de usar o sinal vírgula. Também, pode-se utilizar outro caractere como separador de colunas, e, assim o `csv` passa a ser chamado por alguns como "character-separated-values".

Por ser bastante difundido e de fácil manipulação (a depender do tamanho do arquivo, é possível abrir em um bloco de notas, fazer uma leitura humana, e inclusive editar o arquivo de dados csv), a maioria dos softwares e aplicativos, tem suporte para leitura e gravação de arquivos csv.

No `csv`, cada linha representa um registro, e os valores dos campos associados a esses registros são separados por vírgula (ou ponto e vírgula ou outro caractere). Por exemplo, suponha que seja de interesse, armazenar em um arquivo `csv` com informações básicas das últimas 5 copas do mundo de futebol masculino da FIFA. Para tanto, bastaria abrir um bloco de notas, digitar o texto abaixo e depois salvar com a extensão `.csv`:

```
sede,campeão,ano
Rússia,França,2018
Brasil,Alemanha,2014
África do Sul,Espanha,2010
Alemanha,Itália,2006
Coréia do Sul e Japão,Brasil,2002

```
Porém, apesar das diversas vantagens, quando o número de registros e de campos aumentam de forma considerável, a leitura desses arquivos passam a ter custo computacional elevado, pois o `csv` é um arquivo “row oriented dataset” (ou ainda chamado também de “row storage”), ou seja, como o próprio nome define, é conjunto de dados orientados a linha, e assim, a leitura do arquivo é feito linha a linha. Portanto, mesmo que o interesse de análise seja de uma ou de algumas colunas específicas, todas as colunas serão lidas, diminuindo assim a performance. 

Então, o formato de arquivos Apache parquet, que é um "column oriented dataset”, ou seja, conjunto de dados orientado a colunas, se torna uma excelente alternativa ao `.csv` para gravar grandes conjuntos de dados para análise, pois, além de leitura mais rápida, a taxa de compressão desses arquivos é muito maior em relação aos `.csv` ocupando menos espaço em disco.

De acordo com o site do projeto (https://parquet.apache.org/): *"Apache Parquet is a columnar storage format available to any project in the Hadoop ecosystem, regardless of the choice of data processing framework, data model or programming language"*, ou seja, é um formato de armazenamento colunar, disponível para qualquer projeto do ecossistema Hadoop, independente da escolha da estrutura de processamento dos dados, do modelo dos dados ou da linguagem de progamação.

## O conjunto de dados de exemplo

Vamos utilizar como exemplo, dados do censo escolar 2019, realizado pelo Ministério da Educação do Brasil. Os microdados, são disponibilizados para download no site do INEP - Instituto Nacional de Estudos e Pesquisas Educacionais Anísio Teixeira.

O download é de um arquivo `microdados_educacao_basica_2019` compactado com extensão `.zip`, cujo conteúdo é uma pasta `microdados_educacao_basica_2019`contendo quatro outras pastas `ANEXOS`, `DADOS`, `FILTROS`, `LEIA-ME`. 

Na pasta `DADOS` existem 15 conjuntos de dados em formato `.csv`.

Esses conjuntos de dados são relativamente massivos. Por exemplo, o arquivo `MATRICULA_NORDESTE.CSV` que é o conjunto de dados com informações de cada aluno matriculado na educação básica em escolas do Nordeste do Brasil, possui 15.304.589 registros e 103 campos, e, ocupa em disco 3.790.278 KB, ou seja  quase 3,8 Gigabytes.

## O equipamento

Para os testes de performance de leitura e escrita de arquivos `csv` e `parquet`apresentando aqui neste post, foi utilizado um notebook Lenovo, com processador intel core i7-4500U quad-core, , 16Gb de memória RAM e HD com capacidade de 1 Tb.

## Carregando os arquivos `csv` no ambiente R

Como os microdados do Censo Escolar, sao arquivos `csv` com as colunas separadas pelo caracter pipe (`|`), Eles foram carregados no R com a utilização da função `read_delim` da biblioteca `readr`:

``` {.r}
matricula_NE <- readr::read_delim(
  file = "./microdados_educacao_basica_2019/DADOS/DOCENTES_CO.CSV",
  delim = "|"
)
```

A leitura do arquivo `DOCENTES_CO.CSV`, que possui 892.665 registros e 136 campos, e ocupa em disco algo entorno de 268 Mb,  levou 18,49 segundos para ser lido. Segue abaixo algumas estatísticas relacionadas aos datasets do censo escolar disponibilizados pelo INEP, incluindo o tempo de carregamento no ambiente R.

Tabela 1. Informações sobre leituras de arquivos do Censo escolar 2019 no formato `csv` com uso da biblioteca `arrow` no R.
dataset           | registros | campos | tamanho (KB) | tempo de leitura  (segundos)
------------------ | -------: | :----: | ----------: | ---------------:
DOCENTES_CO        |    892.665 | 136    |   285.874 |    18,49
DOCENTES_NORDESTE  |  3.044.057 | 136    |   964.596 |    66,19
DOCENTES_NORTE     |  1.067.901 | 136    |   341.999 |    22,83
DOCENTES_SUDESTE   |  4.653.852 | 136    | 1.478.987 |    84,88
DOCENTES_SUL       |  1.879.896 | 136    |   600.905 |    37,47
ESCOLAS            |    228.521 | 234    |   108.590 |     9,63
GESTOR             |    187.740 |  83    |    41.668 |     3,39
TURMAS             |  2.432.438 |  79    |   450.988 |    30,79
MATRICULA_CO       |  3.945.797 | 103    |   975.562 |    71,89
MATRICULA_NORDESTE | 15.304.589 | 103    | 3.790.278 | 2.351,71
MATRICULA_NORTE    |  5.198.366 | 103    | 1.289.161 |    77,32
MATRICULA_SUDESTE  | 19.785.845 | 103    | 4.803.374 | 4.740,87
MATRICULA_SUL      |  6.932.126 | 103    | 1.703.439 |   142,68

Vale ressaltar que o readr não conseguiu ler o arquivo `MATRICULA_NORDESTE`, `MATRICULA_SUDESTE` e `MATRICULA_SUL`, e assim, a leitura foi feita com a biblioteca `arrow` através da função `read_delim_arrow`, cujo argumentos são os mesmos da `read_delim` do `readr`.

## Salvando dados em arquivos Parquet com Apache Arrow no R

Existe uma biblioteca no R, de nome `arrow`, que possui duas funções de fácil utilização, para leitura e escrita de arquivos no formato parquet, respectivamente `read_parquet` e `write_parquet`. Para ter acesso a essas funções, primeiro instale a biblioteca `arrow`:

``` {.r}
install.packages("arrow")
```

Com a biblioteca `arrow` já devidamente instalada, para gravar o dataframe disponível em memória em um arquivo parquet no disco, passe como argumento `x` da função `write_parquet` o nome do dataframe que deseja salvar, e no argumento `sink` o diretório e o nome do arquivo parquet:

``` {.r}
arrow::write_parquet( 
  x = matricula_NE,
  sink = "./microdados_educacao_basica_2019/DADOS/MATRICULA_NORDESTE.parquet"
)
```

Por exempplo, para o arquivo `MATRICULA_NORDESTE.CSV`, O R demorou 1.227,41 segundos para gravar o dataframe em um arquivo parquet no disco. E, o arquivo parquet ocupou em disco 2.008.247 KB, ou seja um compressão de 47,02%.

Segue abaixo algumas estatísticas relacionadas a gravação em disco de dataframe em formato parquet: 

Tabela 2. Informações sobre escritas de arquivos do Censo escolar 2019 no formato `parquet` com uso da biblioteca `arrow` no R.
dataset           | registros | campos | tamanho do csv (KB) | tamanho do parquet (KB) | Compressão | tempo de gravação (segundos)
------------------ | ---------:| :----: | ----------: | ---------:| :------: | -------:
DOCENTES_CO        |    892.665 | 136    |   285.874  |    31.213 | 89,1%    |     4,91
DOCENTES_NORDESTE  |  3.044.057 | 136    |   964.596  |   122.796 | 87,3%    |    15,16
DOCENTES_NORTE     |  1.067.901 | 136    |   341.999  |    41.464 | 87,9%    |     5,89
DOCENTES_SUDESTE   |  4.653.852 | 136    | 1.478.987  |   151.313 | 89,8%    |    24,14
DOCENTES_SUL       |  1.879.896 | 136    |   600.905  |    78.500 | 86,9%    |    11,20
ESCOLAS            |    228.521 | 234    |   108.590  |    16.943 | 84,4%    |     9,63
GESTOR             |    187.740 |  83    |    41.668  |    10.341 | 75,2%    |     3,39
TURMAS             |  2.432.438 |  79    |   450.988  |    66.316 | 85,3%    |     8,54
MATRICULA_CO       |  3.945.797 | 103    |   975.562  |   323.494 | 66,8%    |    20,43
MATRICULA_NORDESTE | 15.304.589 | 103    | 3.790.278  |   916.171 | 75,8%    |   255,61
MATRICULA_NORTE    |  5.198.366 | 103    | 1.289.161  |   315.049 | 75,6%    |    17,50
MATRICULA_SUDESTE  | 19.785.845 | 103    | 4.803.374  | 1.146.767 | 76,1%    | 1.389,93
MATRICULA_SUL      |  6.932.126 | 103    | 1.703.439  |   409.738 | 75,9%    |    24,07

## Lendo arquivos Parquet com Apache Arrow no R

Agora, se deseja ler um arquivo parquet salvo em disco, passe como argumento `file` da função `read_parquet` o diretório e o nome do arquivo parquet:

``` {.r}
matricula_NE_Parquet <- arrow::read_parquet(
  file = "./microdados_educacao_basica_2019/DADOS/MATRICULA_NORDESTE.parquet"
)
```

Segue abaixo algumas estatísticas relacionadas a leituras dos datasets do censo escolar 2019 salvos em formato parquet, comparando com os gravados em csv:

Tabela 3. Informações sobre leituras de arquivos do Censo escolar 2019 no formato `parquet` com uso da biblioteca `arrow` no R.
dataset           | registros | campos | tempo de leitura do csv  (segundos) | tempo de leitura do parquet  (segundos) | Tempo de Leitura CSV / Tempo de Leitura Parquet
------------------ | -------: | :----: | ----------: | -------: | -------:
DOCENTES_CO        |    892.665 | 136  |    18,49    |   3,03   |   6,10
DOCENTES_NORDESTE  |  3.044.057 | 136  |    66,19    |   9,97   |   6,64  
DOCENTES_NORTE     |  1.067.901 | 136  |    22,83    |   4,14   |   5,51
DOCENTES_SUDESTE   |  4.653.852 | 136  |    84,88    |  13,58   |   6,25
DOCENTES_SUL       |  1.879.896 | 136  |    37,47    |   7,56   |   4,96
ESCOLAS            |    228.521 | 234  |     9,63    |   2,31   |   4,17
GESTOR             |    187.740 |  83  |     3,39    |   1,77   |   1,92
TURMAS             |  2.432.438 |  79  |    30,79    |   7,68   |   4,01
MATRICULA_CO       |  3.945.797 | 103  |    71,89    |  14,02   |   5,13
MATRICULA_NORDESTE | 15.304.589 | 103  | 2.351,71    |  84,27   |  27,91
MATRICULA_NORTE    |  5.198.366 | 103  |    77,32    |  14,27   |   5,42
MATRICULA_SUDESTE  | 19.785.845 | 103  | 4.740,87    | 243,47   |  19,47
MATRICULA_SUL      |  6.932.126 | 103  |   142,68    |  17,80   |   8,02

Vale ressaltar que, se for de interesse ler somente algumas colunas do conjunto de dados, ao usar a função `read_parquet`da biblioteca `arrow`, basta incluir o argumento `col_select` e passar para ele um vetor com os nomes das colunas que deseja ler. Esse argumento também suporta as funções auxiliares de seleção de atributos da função `select`da biblioteca `dplyr` como a `starts_with()`, `ends_with()`, `contains()`, `matches()`, etc.


## Considerações importantes

Ao comparar conjuntos de dados identicos salvos em formatos diferentes (`csv` e `parquet`), percebe-se (vide tabela 2) que os arquivos `parquet` consomem muito menos espaços em disco, visto que os arquivos de armazenamento orientados a colunas tem taxa de compressão maiores do que os orientados a linhas. Isso traz uma vantagem imensa em armazenar dados em formatos `parquet` pois o custo cai significativamente. Pela comparação dos 15 conjuntos de dados do Censo Escolar 2019, verificamos redução média de 81,2% comparando o tamanho de arquivos `parquet`em relação ao formato `csv`.

Outro fato que chama atenção é que, mesmo quando se tem conjunto de dados com os mesmo registros e colunas  porém salvos em formato diferentes, a leitura de arquivos parquet é mais rápida que de arquivos csv, este último chegando a ter leitura quase 30 vezes mais demorada.

Ainda, vale destacar que para tarefas, onde na maioria das vezes não são utilizadas todas as colunas do conjunto de dados para conduzir uma análise, o fato do parquet ser um formato de arquivo orientado a colunas, pode ser lido somente as colunas de interesse, diminuindo assim o tempo de leitura do arquivo, bem como consumindo menos recursos computacional, levando novamente vantagem em relação ao `csv` que teria que varrer todo o conjunto de dados para depois manter somente as colunas de interesse, resultando em gasto de tempo e de recurso computacional.
